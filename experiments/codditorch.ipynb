{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandboxing some pytorch and pyro stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Blitz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is pytorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's omit this shit..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUTOGRAD: Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scalar function grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddBackward0 at 0x7fcd52dd5860>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y*y*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward(torch.tensor(2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 9.],\n",
      "        [9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vector function grad..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([1., 2., 3.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=2*x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.,  8., 24.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.tensor([1., 1., 2.])\n",
    "y.backward(v)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0., 0.], [1., 0]], requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=1.\n",
    "u = beta * ((x[0,:] - x[1,:]).norm(p=2) - 1.1)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2000,  0.0000],\n",
       "        [-0.2000,  0.0000]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for simplicity's sake, let's create a 1-dimensional potential..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0., 0.], [1., 0.], [0., 1.]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "pyro.set_rng_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.2520) tensor(0.9507)\n"
     ]
    }
   ],
   "source": [
    "#draw a sample from a standard normal\n",
    "loc=0; scale=1.\n",
    "normal=torch.distributions.Normal(loc, scale)\n",
    "x=normal.rsample()\n",
    "energy=-normal.log_prob(x)\n",
    "print(x, energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather():\n",
    "    cloudy=pyro.sample('cloudy', pyro.distributions.Bernoulli(0.3))\n",
    "    cloudy='cloudy' if cloudy.item()==1. else 'sunny'\n",
    "    mean_temp={'cloudy':55., 'sunny': 75.}['cloudy']\n",
    "    scale_temp = {'cloudy': 10.0, 'sunny': 15.0}[cloudy]\n",
    "    temp = pyro.sample('temp', pyro.distributions.Normal(mean_temp, scale_temp))\n",
    "    return cloudy, temp.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sunny', 48.44023513793945)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4867)\n"
     ]
    }
   ],
   "source": [
    "def normal_product(loc, scale):\n",
    "    z1 = pyro.sample(\"z1\", pyro.distributions.Normal(loc, scale))\n",
    "    z2 = pyro.sample(\"z2\", pyro.distributions.Normal(loc, scale))\n",
    "    y = z1 * z2\n",
    "    return y\n",
    "\n",
    "def make_normal_normal():\n",
    "    mu_latent = pyro.sample(\"mu_latent\", pyro.distributions.Normal(0, 1))\n",
    "    fn = lambda scale: normal_product(mu_latent, scale)\n",
    "    return fn\n",
    "\n",
    "print(make_normal_normal()(1.))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVI part 1: an intro to stochastic variational inference in pyro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we define a joint distribution $$p(x, z | \\theta) = p(x|z, \\theta)p(z|\\theta)$$\n",
    "where we want to maximize the log evidence (i.e. $\\log p(x|\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model` is the posterior, whereas `guide` is a family of distributions $q_{\\phi}(z)$ that can be optimized w.r.t. $\\phi$ (i.e. the variational parameters).  To be concrete, we need to be able to compute the distribution of the latent variables given the data (aka the posterior)\n",
    "$$p(z|x, \\theta) = \\frac {p(x, z | \\theta)}  {\\int dz p(x, z | \\theta)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ELBO (Evidence Lower Bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "ELBO =\n",
    "\\langle\n",
    "\\log p(x, z | \\theta) - \\log q_{\\phi}(z)\n",
    "\\rangle\n",
    "_{q_{\\phi}(z)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to do VI, we use `SVI`, which supports ELBO optimization.<br>\n",
    "The user needs to provide the model, the guide, and the optimizer..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import pyro\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Coin Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you have a 2 sided coin and you want to determine whether it's fair; really, you are trying to determine the latent bias parameter;<br>\n",
    "- encode heads and tails as 1 ,0 <br>\n",
    "- the fairness is $f$, where $f \\in \\left[ 0.0, 1.0 \\right]$\n",
    "- our prior $p(f) = \\text{Beta}(10, 10)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.linspace(0,1)\n",
    "beta = pyro.distributions.Beta(10, 10)\n",
    "log_probs = torch.tensor([beta.log_prob(x) for x in xs[1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'prior')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = torch.linspace(0,1)\n",
    "beta = pyro.distributions.Beta(10, 10)\n",
    "log_probs = torch.tensor([beta.log_prob(x) for x in xs[1:-1]])\n",
    "plt.plot(xs[1:-1], np.exp(log_probs))\n",
    "plt.xlabel('f')\n",
    "plt.ylabel(\"p(f)\")\n",
    "plt.title(f\"prior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's say we have collected the data in a list; let's write the corresponding model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.distributions as dist\n",
    "import torch.distributions.constraints as constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data):\n",
    "    \"\"\"\n",
    "    the model is the product of the likelihood and the prior;\n",
    "    define samples of the likelihood with `obs` arg for all of the data\n",
    "    \"\"\"\n",
    "    alpha0 = torch.tensor(10.) #alpha hyperparam\n",
    "    beta0 = torch.tensor(10.) #beta hyperparam\n",
    "    \n",
    "    #sample an f from the prior given prior hyperparams\n",
    "    f = pyro.sample('latent fairness', dist.Beta(alpha0, beta0))\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        pyro.sample(f\"obs_{i}\", dist.Bernoulli(f), obs=data[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide(data):\n",
    "    \"\"\"\n",
    "    define a guide, which is a family of distributions on the latent variables\n",
    "    that is parameterized by `\\phi` variables\n",
    "    \"\"\"\n",
    "    #in this case, we are going to optimize 2 parameters: alpha_q and beta_q\n",
    "    #and the parameters will parameterize a family of distributions of the beta form\n",
    "    \n",
    "    alpha_q = pyro.param('alpha_q', torch.tensor(15.), constraint=constraints.positive)\n",
    "    beta_q = pyro.param('beta_q', torch.tensor(15.), constraint=constraints.positive)\n",
    "    \n",
    "    #and just sample the latent fairness from the distribution\n",
    "    pyro.sample('latent_fairness', dist.Beta(alpha_q, beta_q))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- the model and the guide have the same latent variable names\n",
    "- the model is not an explicit function of the latent variable, but instead set by data\n",
    "- the guide also holds `data` arguments\n",
    "- the variational parameters are torch tensors, and `pyro.param` automatically sets `requires_grad` to `True`\n",
    "- we put positive constraints on the variational parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can to Stochastic Variational Inference (SVI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we just need to add some data first..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for _ in range(6):\n",
    "    data.append(torch.tensor(1.))\n",
    "for _ in range(4):\n",
    "    data.append(torch.tensor(0.))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:27<00:00, 179.61it/s]\n"
     ]
    }
   ],
   "source": [
    "adam_params = {'lr': 5e-4, 'betas': (0.9, 0.999)}\n",
    "optimizer=Adam(adam_params)\n",
    "\n",
    "svi=SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "n_steps=5000\n",
    "for step in tqdm.trange(n_steps):\n",
    "    svi.step(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "based on the data and our prior belief, the fairness of the coin is 0.502 +- 0.258\n"
     ]
    }
   ],
   "source": [
    "alpha_q = pyro.param('alpha_q').item()\n",
    "beta_q = pyro.param('beta_q').item()\n",
    "# here we use some facts about the beta distribution\n",
    "# compute the inferred mean of the coin's fairness\n",
    "inferred_mean = alpha_q / (alpha_q + beta_q)\n",
    "# compute inferred standard deviation\n",
    "factor = beta_q / (alpha_q * (1.0 + alpha_q + beta_q))\n",
    "inferred_std = inferred_mean * np.sqrt(factor)\n",
    "\n",
    "print(\"\\nbased on the data and our prior belief, the fairness \" +\n",
    "      \"of the coin is %.3f +- %.3f\" % (inferred_mean, inferred_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVI part 2: conditional independence, subsampling, and amortization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for models with N observables, running `model` and `guide` requires `ELBO` estimates that scales poorly with N; but we can subsample in batches provided that there are some conditional independencies that we can take advantage of.  <br>\n",
    "\n",
    "For example, if the observations are conditionally independent given latent variables, the log likelihood can be approximated as\n",
    "$$\n",
    "\\sum_{i=1}^{N}\\ln p(x_i|z) \\approx \\frac{N}{M} \\sum_{i \\in I_M} \\ln p(x_i|z)\n",
    "$$\n",
    "where $I_M$ is a minibatch of the N data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for some reason in pyro, it is necessary to explcitly replace the `for` loop in `model` (the one that adds the data as `obs`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data):\n",
    "    \"\"\"\n",
    "    the model is the product of the likelihood and the prior;\n",
    "    define samples of the likelihood with `obs` arg for all of the data\n",
    "    \"\"\"\n",
    "    alpha0 = torch.tensor(10.) #alpha hyperparam\n",
    "    beta0 = torch.tensor(10.) #beta hyperparam\n",
    "    \n",
    "    #sample an f from the prior given prior hyperparams\n",
    "    f = pyro.sample('latent fairness', dist.Beta(alpha0, beta0))\n",
    "    \n",
    "#     for i in range(len(data)):\n",
    "#         pyro.sample(f\"obs_{i}\", dist.Bernoulli(f), obs=data[i])\n",
    "\n",
    "    #the above code has to be replaced with \n",
    "    for i in pyro.plate('data_loop', len(data)):\n",
    "        pyro.sample(f\"obs_{i}\", dist.Bernoulli(f), obs=data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as a note, you can also vectorize `plate` like such:<br>\n",
    "```\n",
    "data=torch.zeros(10)\n",
    "data[:6]=torch.ones()\n",
    "with plate('observed_data'):\n",
    "    pyro.sample('obs', dist.Bernoulli(f), obs=data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### subsamping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subsample to run on large datasets...<br>\n",
    "simply put, we can just subsample in the plate...<br>\n",
    "```\n",
    "for i in pyro.plate(\"data_loop\", len(data), subsample_size=5):\n",
    "    pyro.sample(\"obs_{}\".format(i), dist.Bernoulli(f), obs=data[i])\n",
    "```\n",
    "which,by the way, does automatic scaling;<br>\n",
    "this can also be vectorized...<br>\n",
    "```\n",
    "with plate('observe_data', size=10, subsample_size=5) as ind:\n",
    "    pyro.sample('obs', dist.Bernoulli(f),\n",
    "                obs=data.index_select(0, ind))\n",
    "```\n",
    "However, if the data size is really big, theres a nonnegligible probability tat some dat apoints will never have been subsampled; you can use the `subsample` argument in `plate`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
